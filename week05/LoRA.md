# LoRA

Low-Rank Adaptation，是一种微调大模型预训练的技术。它的核心思想是通过低秩分解减少微调时的参数量，而不牺牲模型的性能。

## 为什么需要LoRA

大模型的大，不仅体现在其参数量上，更体现在我们无法轻松进行微调。全量微调是一个预训练大模型的代价非常高，而且一般的设备根本训练不动。LoRA提供了一种高效的微调方法，使得在小型设备上微调大模型成为可能。

## LoRA的核心思想

LoRA的核心在于利用低秩分解来近似模型权重的更新。**过参数化**模型的学习特征为于一个低维的内在子空间。

### 低秩分解

在LoRA中，**模型适配或者微调过程中，权重的变化**同样是低秩的。基于这个假设，权重矩阵 w 的更新可以近似表示为两个小矩阵 B 和 A 的乘积：
$$
\Delta W = BA
$$
其中：

- A ∈ R^rxd^ , r 是低秩值 ，d 是输入特征维度
- B ∈ R^kxr^ , k 时输出特征维度

通过训练这两个小矩阵，我门可以近似低更新原始权重矩阵 w，而无需训练整个大的 w。

### 应用到神经网络中的线性层

在线性层，前向传播的计算为：
$$
y = Wx + b
$$
在微调过程中，通常需要更新 w 和 b 。但在 LoRA 中，我们可以冻结原始的 W，仅仅在其基础上添加一个可训练的赠量：$\Delta W$:
$$
y = (W + \Delta W)x + b
$$
其中：
$$
\Delta W = BA
$$
通过训练 A 和 B，我们大大减少了需要更新的参数数量。

> 不增加推理延迟。只有在推理前把 LoRA 训练得到的增量矩阵 $\Delta W$ 加回原始参数 W，才能恢复为一个普通模型结构，避免额外计算。

假设：

- 输入特征维度 d=1024
- 输出特征维度 k=1024
- 低秩值 r=4

**全量微调参数量：**

- 权重参数: 1024×1024=1,048,576
- 偏置参数: 1024
- **总参数量: 1,048,576+1024=1,049,600**

**使用 LoRA 微调参数量：**

- 矩阵 A 参数: 4×1024=4,096
- 矩阵 B 参数: 1024×4=4,096
- 偏置参数: 1024
- **总参数量: 4,096+4,096+1024=9,216**

**参数量对比：**

- 全量微调: 1,049,600 参数
- LoRA 微调: 9,216 参数
- **参数减少比例: 9,2161,049,600≈0.0088**

也就是说，使用 LoRA 后，参数量减少了约 **114 倍**，即参数量仅为原来的 **0.88**。

<img src="/Users/edward_beck8n24/Library/Application Support/typora-user-images/image-20250702153114688.png" alt="image-20250702153114688" style="zoom:50%;" />

## 为什么只导入 LoRA 模型不能生图

LoRA 模型只是对原始模型的权重更新进行了低秩近似，存储了权重的增量部分 $\Delta W$, 而不是完整的模型权重 w。

- 仅仅加载 LoRA 模型是无法进行推理的，必须结合原始的预训练模型一起使用。

LoRA 模型就像是给一幅画添加“修改指令”，这些指令需要在原画的基础上才能生效。如果你只有修改指令（LoRA），却没有原画（预训练模型），那么无法得到最终的作品。



