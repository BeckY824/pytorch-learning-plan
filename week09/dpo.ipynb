{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4452bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, GenerationConfig\n",
    "from trl import DPOConfig, DPOTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24596a",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ca418",
   "metadata": {},
   "source": [
    "使用预先提供的数据集，其中包括带标签的偏好数据集（labelled_data.json）和测试提示数据（test_prompt.json）。改数据集讨论是否 “真人化动漫”，其中两个回答分别对应支持和不支持（由chatgpt生成），在后面的代码我们需要调整支持的占比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ff885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./GenAI_hw6_dataset/labelled_data.json\", 'r') as jsonfile:\n",
    "    full_data = json.load(jsonfile)\n",
    "\n",
    "with open(\"./GenAI_hw6_dataset/test_prompt.json\", 'r') as jsonfile:\n",
    "    test_data = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fa5d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'prompt': '日本動漫真人化是否有損原作形象？',\n",
       "  'support': '真人化能夠呈現更真實的角色形象，提升原作魅力。',\n",
       "  'oppose': '真人化可能無法完美呈現動畫中的獨特風格，損害原作形象。'},\n",
       " {'id': 2,\n",
       "  'prompt': '真人化是否能夠擴大動漫在全球的影響力？',\n",
       "  'support': '真人化能夠讓更多非動漫迷接觸作品，擴大影響力。',\n",
       "  'oppose': '真人化可能失去動漫的獨特風格，限制影響力擴大。'},\n",
       " {'id': 3,\n",
       "  'prompt': '真人化是否能夠吸引新觀眾？',\n",
       "  'support': '真人化能夠吸引不熟悉動漫的觀眾，擴大受眾。',\n",
       "  'oppose': '真人化可能讓原本的動漫迷感到失望，無法吸引新觀眾。'},\n",
       " {'id': 4,\n",
       "  'prompt': '真人化是否能夠保留原作故事情節的精髓？',\n",
       "  'support': '真人化有機會更深入挖掘原作故事，保留精髓。',\n",
       "  'oppose': '真人化可能因為改編而失去原作故事的深度與精髓。'},\n",
       " {'id': 5,\n",
       "  'prompt': '真人化是否能夠提升動漫產業的商業價值？',\n",
       "  'support': '真人化能夠開拓更多商業機會，提升產業價值。',\n",
       "  'oppose': '真人化可能讓觀眾對原作失去興趣，影響產業價值。'},\n",
       " {'id': 6,\n",
       "  'prompt': '真人化是否能夠保持原作的文化特色？',\n",
       "  'support': '真人化可以透過場景、服裝等元素保留文化特色。',\n",
       "  'oppose': '真人化可能因為文化差異而失去原作獨有的文化魅力。'},\n",
       " {'id': 7,\n",
       "  'prompt': '真人化是否能夠挑戰技術上的新突破？',\n",
       "  'support': '真人化促使技術創新，挑戰視覺效果上的新高度。',\n",
       "  'oppose': '真人化可能因為技術限制而無法達到動畫中的視覺效果。'},\n",
       " {'id': 8,\n",
       "  'prompt': '真人化是否會受到演員選擇的爭議？',\n",
       "  'support': '演員選擇可因應市場需求，不必受限於動畫形象。',\n",
       "  'oppose': '演員選擇可能引起爭議，觀眾難以接受角色塑造。'},\n",
       " {'id': 9,\n",
       "  'prompt': '真人化是否能夠提高動漫的社會認同度？',\n",
       "  'support': '真人化有機會讓更多人接受動漫，提高社會認同度。',\n",
       "  'oppose': '真人化可能因為劇情改編而無法贏得社會認同。'},\n",
       " {'id': 10,\n",
       "  'prompt': '真人化是否能夠保留原作角色的個性特色？',\n",
       "  'support': '真人化可以透過演員表現保留角色的個性特色。',\n",
       "  'oppose': '真人化可能因演員演技或導演選擇而失去角色的原有特色。'},\n",
       " {'id': 11,\n",
       "  'prompt': '真人化是否會影響原作動畫的收視率？',\n",
       "  'support': '真人化可能吸引更廣泛的觀眾群，提高收視率。',\n",
       "  'oppose': '真人化可能因為原作粉絲的反感而影響動畫收視率。'},\n",
       " {'id': 12,\n",
       "  'prompt': '真人化是否會受到版權問題的困擾？',\n",
       "  'support': '版權問題可透過合作與協商解決，不一定成為問題。',\n",
       "  'oppose': '版權問題可能成為真人化的阻礙，影響製作進程。'},\n",
       " {'id': 13,\n",
       "  'prompt': '真人化是否會引起文化觀念差異的爭議？',\n",
       "  'support': '透過適度的改編，真人化可減少文化觀念差異的爭議。',\n",
       "  'oppose': '真人化可能因文化觀念差異引起爭議，影響觀眾接受度。'},\n",
       " {'id': 14,\n",
       "  'prompt': '真人化是否能夠挑戰影片表現的新風格？',\n",
       "  'support': '真人化有機會探索新的視覺風格，豐富影片表現。',\n",
       "  'oppose': '真人化可能受制於原作風格，難以創造新的影片風格。'},\n",
       " {'id': 15,\n",
       "  'prompt': '真人化是否能夠推動動漫產業的多元發展？',\n",
       "  'support': '真人化能夠開啟動漫產業的多元化發展方向。',\n",
       "  'oppose': '真人化可能使觀眾對原作產生固有印象，難以多元發展。'},\n",
       " {'id': 16,\n",
       "  'prompt': '真人化是否會改變原作動畫的風格？',\n",
       "  'support': '真人化可以透過改編風格，呈現不同的視覺風格。',\n",
       "  'oppose': '真人化可能難以完美呈現原作動畫獨有的視覺風格。'},\n",
       " {'id': 17,\n",
       "  'prompt': '真人化是否能夠擴大原作的世界觀？',\n",
       "  'support': '真人化有機會透過實景呈現，擴大原作的世界觀。',\n",
       "  'oppose': '真人化可能因製作預算或技術限制無法展現原作的豐富世界觀。'},\n",
       " {'id': 18,\n",
       "  'prompt': '真人化是否能夠吸引更多投資進入動漫產業？',\n",
       "  'support': '真人化能夠讓更多投資者看到商機，增加投資動機。',\n",
       "  'oppose': '真人化可能因觀眾反感而使投資者對動漫產業失去信心。'},\n",
       " {'id': 19,\n",
       "  'prompt': '真人化是否能夠促進原作動畫的衍生品銷售？',\n",
       "  'support': '真人化能夠擴大原作品牌影響力，提高衍生品銷售。',\n",
       "  'oppose': '真人化可能因觀眾對原作失望而降低衍生品銷售。'},\n",
       " {'id': 20,\n",
       "  'prompt': '真人化是否能夠提升動漫的社會地位？',\n",
       "  'support': '真人化有機會使動漫更受社會重視，提升地位。',\n",
       "  'oppose': '真人化可能讓觀眾對動漫產生負面印象，降低社會地位。'},\n",
       " {'id': 21,\n",
       "  'prompt': '真人化是否會破壞原作動畫的獨特性？',\n",
       "  'support': '真人化可以透過新的呈現方式，保留原作的獨特性。',\n",
       "  'oppose': '真人化可能因為改編而使原作失去獨特風格。'},\n",
       " {'id': 22,\n",
       "  'prompt': '真人化是否能夠促進動漫產業的國際交流？',\n",
       "  'support': '真人化能夠使動漫更容易被國際觀眾理解，促進交流。',\n",
       "  'oppose': '真人化可能因文化差異而難以打開國際市場，限制交流。'},\n",
       " {'id': 23,\n",
       "  'prompt': '真人化是否會影響原作動畫的經典地位？',\n",
       "  'support': '真人化可以為原作注入新活力，提升經典地位。',\n",
       "  'oppose': '真人化可能因改編而被視為是對原作經典的不敬。'},\n",
       " {'id': 24,\n",
       "  'prompt': '真人化是否會受到粉絲的反感？',\n",
       "  'support': '部分粉絲可能因真人化而感到新鮮，不一定反感。',\n",
       "  'oppose': '部分粉絲可能因真人化而感到失望，產生強烈反感。'},\n",
       " {'id': 25,\n",
       "  'prompt': '真人化是否能夠挖掘原作未探索的劇情？',\n",
       "  'support': '真人化有機會透過改編劇情，挖掘原作未探索的內容。',\n",
       "  'oppose': '真人化可能因為劇情改編而失去原作的深度與探索價值。'},\n",
       " {'id': 26,\n",
       "  'prompt': '真人化是否能夠吸引更多知名導演與演員參與？',\n",
       "  'support': '真人化能夠吸引更多知名人士參與，提升製作水平。',\n",
       "  'oppose': '真人化可能因為風險高而難以吸引知名導演與演員參與。'},\n",
       " {'id': 27,\n",
       "  'prompt': '真人化是否會受到動畫粉絲的期待壓力？',\n",
       "  'support': '真人化可以透過適度的改編滿足觀眾期待，降低壓力。',\n",
       "  'oppose': '真人化可能因無法滿足動畫粉絲的期待而受到極大壓力。'},\n",
       " {'id': 28,\n",
       "  'prompt': '真人化是否有助於促進動漫產業內的技術創新？',\n",
       "  'support': '真人化的製作需求推動了視覺效果和製作技術的創新。',\n",
       "  'oppose': '過分專注於真人化可能會忽視動漫本身的技術創新和發展。'},\n",
       " {'id': 29,\n",
       "  'prompt': '真人化是否會提高動漫文化的普及和接受度？',\n",
       "  'support': '真人化有助於使動漫文化更加普及，吸引更多不同背景的觀眾。',\n",
       "  'oppose': '真人化可能會降低動漫文化的獨特性，減少其對特定群體的吸引力。'},\n",
       " {'id': 30,\n",
       "  'prompt': '真人化是否有助於提升動漫角色的深度和多維度？',\n",
       "  'support': '真人演員的演繹能為動漫角色增添更多層次和深度。',\n",
       "  'oppose': '真人化經常無法徹底展現動漫角色的複雜性和深度。'},\n",
       " {'id': 31,\n",
       "  'prompt': '真人化能增加原作的知名度嗎？',\n",
       "  'support': '真人化能擴大原作的觀眾群，提高其知名度。',\n",
       "  'oppose': '真人化經常失敗，可能損害原作的聲譽。'},\n",
       " {'id': 32,\n",
       "  'prompt': '真人化能夠提高原作的藝術價值嗎？',\n",
       "  'support': '真人化是對原作的新詮釋，能增加其藝術層面的深度。',\n",
       "  'oppose': '真人化往往無法捕捉原作的藝術魅力，反而貶低其價值。'},\n",
       " {'id': 33,\n",
       "  'prompt': '真人化是否利於動漫產業的經濟發展？',\n",
       "  'support': '真人化能創造新的商業機會，刺激動漫產業的經濟增長。',\n",
       "  'oppose': '真人化的商業化導向可能扭曲原作精神，對產業長期發展不利。'},\n",
       " {'id': 34,\n",
       "  'prompt': '真人化是否有助於動漫文化的國際傳播？',\n",
       "  'support': '真人化作品更容易被國際觀眾接受，有助於推廣動漫文化。',\n",
       "  'oppose': '真人化可能會錯誤詮釋動漫文化，造成國際上的誤解。'},\n",
       " {'id': 35,\n",
       "  'prompt': '真人化是否能準確再現動漫的奇幻元素？',\n",
       "  'support': '現代技術能夠精準再現動漫的奇幻元素，增強真人化的吸引力。',\n",
       "  'oppose': '真人化往往無法完美再現動漫的奇幻世界，失去原作魅力。'},\n",
       " {'id': 36,\n",
       "  'prompt': '真人化是否尊重原作的精神和內容？',\n",
       "  'support': '真人化時，製作團隊通常會努力保持對原作的忠誠和尊重。',\n",
       "  'oppose': '真人化經常為了商業利益而改變原作的核心精神和內容。'},\n",
       " {'id': 37,\n",
       "  'prompt': '真人化對原作的完整性有何影響？',\n",
       "  'support': '真人化為原作提供了新的視角，豐富了其敘事和背景。',\n",
       "  'oppose': '真人化往往簡化或改變原作的故事，損害其完整性。'},\n",
       " {'id': 38,\n",
       "  'prompt': '真人化是否有助於吸引更廣泛的觀眾群？',\n",
       "  'support': '真人化能吸引不習慣看動漫的觀眾，擴大受眾基礎。',\n",
       "  'oppose': '真人化可能會失去核心動漫粉絲，而無法吸引新觀眾。'},\n",
       " {'id': 39,\n",
       "  'prompt': '真人化是否有助於提升原創動漫的品牌價值？',\n",
       "  'support': '成功的真人化能提升原創動漫的品牌價值和市場認可。',\n",
       "  'oppose': '不成功的真人化可能損害原創動漫的品牌形象。'},\n",
       " {'id': 40,\n",
       "  'prompt': '真人化是否有助於促進原創作者的創意表達？',\n",
       "  'support': '真人化提供了一個新平台，讓原創作者能夠以不同方式表達創意。',\n",
       "  'oppose': '真人化可能限制或扭曲原創者的創意，使其不再忠實於原作。'},\n",
       " {'id': 41,\n",
       "  'prompt': '真人化是否會增加原作的文化影響力？',\n",
       "  'support': '真人化作品更容易被主流文化接受，增強原作的文化影響力。',\n",
       "  'oppose': '真人化可能會稀釋原作的獨特文化元素，降低其影響力。'},\n",
       " {'id': 42,\n",
       "  'prompt': '真人化是否有助於原作故事的深度和複雜度？',\n",
       "  'support': '真人化可以加深原作的敘事深度，提供更複雜的角色和情節發展。',\n",
       "  'oppose': '真人化經常因時長和預算限制而簡化故事，減少深度和複雜度。'},\n",
       " {'id': 43,\n",
       "  'prompt': '真人化是否有助於動漫產業的多元化發展？',\n",
       "  'support': '真人化作品的多樣性能推動整個動漫產業向更多元化方向發展。',\n",
       "  'oppose': '過度專注於真人化可能會忽視動漫其他領域的發展，限制多元化。'},\n",
       " {'id': 44,\n",
       "  'prompt': '真人化是否有助於提高原作的國際競爭力？',\n",
       "  'support': '真人化能使原作更容易進入國際市場，提高其全球競爭力。',\n",
       "  'oppose': '真人化如果失敗，可能會損害原作在國際市場的聲譽和競爭力。'},\n",
       " {'id': 45,\n",
       "  'prompt': '真人化是否有助於原創作者的經濟利益？',\n",
       "  'support': '真人化的成功能為原創者帶來額外的經濟收益。',\n",
       "  'oppose': '真人化可能會未經原創者充分同意就進行，侵犯其經濟和版權利益。'},\n",
       " {'id': 46,\n",
       "  'prompt': '真人化是否有助於促進動漫和其他媒介的合作？',\n",
       "  'support': '真人化能開啟與電影、電視等其他媒介的合作機會。',\n",
       "  'oppose': '過分依賴真人化可能會忽視動漫本身的獨立性和特色，限制媒介間的真正合作。'},\n",
       " {'id': 47,\n",
       "  'prompt': '真人化是否有助於拓寬動漫的故事敘述方式？',\n",
       "  'support': '真人化提供了一種全新的敘述方式，豐富動漫的故事表達。',\n",
       "  'oppose': '真人化往往受限於現實條件，無法像動漫那樣自由發揮故事敘述。'},\n",
       " {'id': 48,\n",
       "  'prompt': '真人化是否有助於提高動漫角色的真實感？',\n",
       "  'support': '真人演員能賦予動漫角色更多人性化和真實感。',\n",
       "  'oppose': '真人化往往無法完全捕捉到動漫角色的獨特魅力和特性。'},\n",
       " {'id': 49,\n",
       "  'prompt': '真人化是否能夠正確傳達原作的主題和信息？',\n",
       "  'support': '真人化能夠通過實際演繹更加生動地傳達原作的主題和信息。',\n",
       "  'oppose': '真人化經常因為格式和風格限制而失去傳達原作主題的能力。'},\n",
       " {'id': 50,\n",
       "  'prompt': '真人化是否有助於增進原創動漫的社會認知度？',\n",
       "  'support': '真人化能使原創動漫更容易獲得主流社會的認可和關注。',\n",
       "  'oppose': '真人化可能會將動漫文化簡化，降低其在社會中的地位和認知度。'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c8a480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'prompt': '真人化是否能改善日本漫畫的全球可及性？'},\n",
       " {'id': 2, 'prompt': '真人化如何影響年輕一代對日本漫畫的看法？'},\n",
       " {'id': 3, 'prompt': '真人化是否能提升原作漫畫的文學價值？'},\n",
       " {'id': 4, 'prompt': '真人化是否有助於保護和保存日本漫畫的傳統？'},\n",
       " {'id': 5, 'prompt': '真人化是否有助於提升日本漫畫行業的經濟效益？'},\n",
       " {'id': 6, 'prompt': '真人化如何影響日本漫畫原作者的創作動力？'},\n",
       " {'id': 7, 'prompt': '真人化是否對漫畫原作的忠實粉絲公平？'},\n",
       " {'id': 8, 'prompt': '真人化是否能夠促進日本漫畫的創新和多樣性？'},\n",
       " {'id': 9, 'prompt': '真人化是否有助於擴大動漫文化的市場份額？'},\n",
       " {'id': 10, 'prompt': '真人化是否有助於提高日本漫畫在全球的競爭力？'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81493b7b",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## 使用 HFD 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ef4bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 使用MPS加速\n",
      "模型已加载到设备: mps\n",
      "✨ 使用Qwen2-1.5B-Instruct模型，参数量约1.5B（相比之前的7B模型大幅减少）\n"
     ]
    }
   ],
   "source": [
    "# 使用更轻量的Qwen2-1.5B-Instruct模型（相比7B模型大幅减少参数量）\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    '../week06/cache/Qwen2-1.5B-Instruct',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,      # 使用float16减少内存占用\n",
    "    low_cpu_mem_usage=True,         # 降低CPU内存使用\n",
    ")\n",
    "\n",
    "# 移动到MPS设备（如果可用）\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "if device == \"mps\":\n",
    "    model = model.to('mps')\n",
    "    print(\"✅ 使用MPS加速\")\n",
    "else:\n",
    "    print(\"🔄 使用CPU运行\")\n",
    "\n",
    "print(f\"模型已加载到设备: {device}\")\n",
    "print(f\"✨ 使用Qwen2-1.5B-Instruct模型，参数量约1.5B（相比之前的7B模型大幅减少）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8286f7",
   "metadata": {},
   "source": [
    "## 查看未经过微调的模型原始输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "900fdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../week06/cache/Qwen2-1.5B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff40d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_formulate(data):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": '回覆請少於20字'},\n",
    "        {\"role\": \"user\", \"content\": data['prompt']},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d844fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "真人化是否能改善日本漫畫的全球可及性？\n",
      "⏳ 开始处理问题 1...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:09,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 1 完成，耗时: 1.03秒\n",
      "Response from original model:\n",
      "是的，真人化可以增加漫畫的視覺吸引力和可觀賞性。\n",
      "\n",
      "Question 2:\n",
      "真人化如何影響年輕一代對日本漫畫的看法？\n",
      "⏳ 开始处理问题 2...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 2 完成，耗时: 0.72秒\n",
      "Response from original model:\n",
      "真人化使漫畫更接近生活，吸引年輕觀眾。\n",
      "\n",
      "Question 3:\n",
      "真人化是否能提升原作漫畫的文學價值？\n",
      "⏳ 开始处理问题 3...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 3 完成，耗时: 0.95秒\n",
      "Response from original model:\n",
      "真人化可以增加觀眾的接觸度，但不一定提升原作的文學價值。\n",
      "\n",
      "🧹 执行内存清理\n",
      "Question 4:\n",
      "真人化是否有助於保護和保存日本漫畫的傳統？\n",
      "⏳ 开始处理问题 4...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:03<00:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 4 完成，耗时: 0.93秒\n",
      "Response from original model:\n",
      "是的，真人化有助於保持漫畫的傳統風格和故事性。\n",
      "\n",
      "Question 5:\n",
      "真人化是否有助於提升日本漫畫行業的經濟效益？\n",
      "⏳ 开始处理问题 5...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:04<00:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 5 完成，耗时: 0.85秒\n",
      "Response from original model:\n",
      "是的，真人化可以增加觀眾吸引力和收視率。\n",
      "\n",
      "Question 6:\n",
      "真人化如何影響日本漫畫原作者的創作動力？\n",
      "⏳ 开始处理问题 6...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:05<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 6 完成，耗时: 0.72秒\n",
      "Response from original model:\n",
      "真人化增加創作靈感，但可能影響創作風格。\n",
      "\n",
      "🧹 执行内存清理\n",
      "Question 7:\n",
      "真人化是否對漫畫原作的忠實粉絲公平？\n",
      "⏳ 开始处理问题 7...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:06<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 7 完成，耗时: 0.61秒\n",
      "Response from original model:\n",
      "真人化可能影響原作的深度和細節。\n",
      "\n",
      "Question 8:\n",
      "真人化是否能夠促進日本漫畫的創新和多樣性？\n",
      "⏳ 开始处理问题 8...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:06<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 8 完成，耗时: 0.62秒\n",
      "Response from original model:\n",
      "是的，真人化有助於展現更多樣性。\n",
      "\n",
      "Question 9:\n",
      "真人化是否有助於擴大動漫文化的市場份額？\n",
      "⏳ 开始处理问题 9...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 9 完成，耗时: 0.76秒\n",
      "Response from original model:\n",
      "是的，真人化可以增加動漫的吸引力和接受度。\n",
      "\n",
      "🧹 执行内存清理\n",
      "Question 10:\n",
      "真人化是否有助於提高日本漫畫在全球的競爭力？\n",
      "⏳ 开始处理问题 10...\n",
      "🔄 处理输入...\n",
      "✅ 输入处理完成，设备: mps\n",
      "🤖 开始生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 解码输出...\n",
      "✅ 问题 10 完成，耗时: 0.74秒\n",
      "Response from original model:\n",
      "是的，真人化可以增加漫畫的吸引力和接受度。\n",
      "\n",
      "🎉 所有问题处理完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "\n",
    "original_model_response = []\n",
    "\n",
    "# 确定设备\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "for data in tqdm(test_data):\n",
    "    id = data['id']\n",
    "    print(f\"Question {id}:\\n{data['prompt']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"⏳ 开始处理问题 {id}...\")\n",
    "    \n",
    "    # 正确处理输入设备分配\n",
    "    print(\"🔄 处理输入...\")\n",
    "    inputs = tokenizer(data_formulate(data), return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    print(f\"✅ 输入处理完成，设备: {device}\")\n",
    "    \n",
    "    generation_config = GenerationConfig(\n",
    "        do_sample=False,\n",
    "        max_new_tokens=50,  # 减少生成长度，提高速度\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id  # 添加结束token\n",
    "    )\n",
    "    \n",
    "    print(\"🤖 开始生成...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, generation_config=generation_config)\n",
    "        \n",
    "        print(\"📝 解码输出...\")\n",
    "        output_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # 更安全的文本分割方式（适配Qwen2模型）\n",
    "        prompt_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
    "        \n",
    "        if 'assistant\\n' in output_text:\n",
    "            # Qwen2模型的输出格式\n",
    "            parts = output_text.split('assistant\\n')\n",
    "            if len(parts) > 1:\n",
    "                output_text = parts[-1].strip()\n",
    "            else:\n",
    "                output_text = output_text.replace(prompt_text, '').strip()\n",
    "        elif '[/INST] ' in output_text:\n",
    "            # 兼容其他模型的分隔符\n",
    "            output_text = output_text.split('[/INST] ')[1]\n",
    "        else:\n",
    "            # 简单方式：移除prompt部分\n",
    "            output_text = output_text.replace(prompt_text, '').strip()\n",
    "        \n",
    "        original_model_response.append(output_text)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"✅ 问题 {id} 完成，耗时: {elapsed:.2f}秒\")\n",
    "        print(f\"Response from original model:\\n{output_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成时出错: {e}\")\n",
    "        original_model_response.append(\"生成失败\")\n",
    "        continue\n",
    "    \n",
    "    # 内存清理\n",
    "    if device == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    elif torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 每处理几个样本后清理一次内存\n",
    "    if id % 3 == 0:\n",
    "        gc.collect()\n",
    "        print(\"🧹 执行内存清理\")\n",
    "\n",
    "print(\"🎉 所有问题处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f792aa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"🔄 强制使用CPU以提高稳定性\")\\nmodel = model.to(\"cpu\")\\ndevice = \"cpu\"\\n\\noriginal_model_response = []\\n\\n# 先测试单个问题\\ntest_single = test_data[0]\\nprint(f\"测试问题: {test_single[\\'prompt\\']}\")\\n\\ninputs = tokenizer(data_formulate(test_single), return_tensors=\"pt\")\\n\\ngeneration_config = GenerationConfig(\\n    do_sample=False,\\n    max_new_tokens=20,  # 很短的输出\\n    pad_token_id=tokenizer.pad_token_id\\n)\\n\\nprint(\"开始生成...\")\\nstart_time = time.time()\\nwith torch.no_grad():\\n    output = model.generate(**inputs, generation_config=generation_config)\\nprint(f\"生成完成，耗时: {time.time() - start_time:.2f}秒\")\\n\\noutput_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\\nif \\'[/INST] \\' in output_text:\\n    output_text = output_text.split(\\'[/INST] \\')[1]\\n\\nprint(f\"输出: {output_text}\")\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果上面的代码仍然运行缓慢，可以尝试这个简化版本（强制使用CPU）\n",
    "# 取消注释下面的代码来运行\n",
    "\n",
    "\"\"\"\n",
    "print(\"🔄 强制使用CPU以提高稳定性\")\n",
    "model = model.to(\"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "original_model_response = []\n",
    "\n",
    "# 先测试单个问题\n",
    "test_single = test_data[0]\n",
    "print(f\"测试问题: {test_single['prompt']}\")\n",
    "\n",
    "inputs = tokenizer(data_formulate(test_single), return_tensors=\"pt\")\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,  # 很短的输出\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "print(\"开始生成...\")\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, generation_config=generation_config)\n",
    "print(f\"生成完成，耗时: {time.time() - start_time:.2f}秒\")\n",
    "\n",
    "output_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "if '[/INST] ' in output_text:\n",
    "    output_text = output_text.split('[/INST] ')[1]\n",
    "\n",
    "print(f\"输出: {output_text}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7730ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果已保存到:\n",
      "📄 JSON格式: ./results/qwen2_responses_20250807_134157.json\n",
      "📝 文本格式: ./results/qwen2_responses_20250807_134157.txt\n",
      "\n",
      "📊 统计信息:\n",
      "- 总问题数: 10\n",
      "- 成功回答数: 10\n",
      "- 使用设备: mps\n",
      "- 模型: Qwen2-1.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# 保存结果到文件\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 创建结果目录\n",
    "results_dir = \"./results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 生成时间戳\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 准备保存的数据\n",
    "results_data = {\n",
    "    \"model_name\": \"Qwen2-1.5B-Instruct\",\n",
    "    \"model_path\": \"../week06/cache/Qwen2-1.5B-Instruct\",\n",
    "    \"timestamp\": timestamp,\n",
    "    \"device\": device,\n",
    "    \"total_questions\": len(test_data),\n",
    "    \"successful_responses\": len([r for r in original_model_response if r != \"生成失败\"]),\n",
    "    \"results\": []\n",
    "}\n",
    "\n",
    "# 组合问题和答案\n",
    "for i, data in enumerate(test_data):\n",
    "    result_item = {\n",
    "        \"id\": data['id'],\n",
    "        \"question\": data['prompt'],\n",
    "        \"response\": original_model_response[i] if i < len(original_model_response) else \"未生成\",\n",
    "        \"status\": \"success\" if i < len(original_model_response) and original_model_response[i] != \"生成失败\" else \"failed\"\n",
    "    }\n",
    "    results_data[\"results\"].append(result_item)\n",
    "\n",
    "# 保存为JSON文件\n",
    "json_filename = f\"{results_dir}/qwen2_responses_{timestamp}.json\"\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 保存为文本文件（更易读）\n",
    "txt_filename = f\"{results_dir}/qwen2_responses_{timestamp}.txt\"\n",
    "with open(txt_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"Qwen2-1.5B-Instruct 模型推理结果\\n\")\n",
    "    f.write(f\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"时间: {timestamp}\\n\")\n",
    "    f.write(f\"设备: {device}\\n\")\n",
    "    f.write(f\"模型路径: ../week06/cache/Qwen2-1.5B-Instruct\\n\")\n",
    "    f.write(f\"总问题数: {len(test_data)}\\n\")\n",
    "    f.write(f\"成功回答数: {len([r for r in original_model_response if r != '生成失败'])}\\n\")\n",
    "    f.write(f\"\\n详细结果:\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    \n",
    "    for i, data in enumerate(test_data):\n",
    "        f.write(f\"\\n问题 {data['id']}: {data['prompt']}\\n\")\n",
    "        response = original_model_response[i] if i < len(original_model_response) else \"未生成\"\n",
    "        f.write(f\"回答: {response}\\n\")\n",
    "        f.write(\"-\"*30 + \"\\n\")\n",
    "\n",
    "print(f\"✅ 结果已保存到:\")\n",
    "print(f\"📄 JSON格式: {json_filename}\")\n",
    "print(f\"📝 文本格式: {txt_filename}\")\n",
    "\n",
    "# 显示保存的统计信息\n",
    "print(f\"\\n📊 统计信息:\")\n",
    "print(f\"- 总问题数: {len(test_data)}\")\n",
    "print(f\"- 成功回答数: {len([r for r in original_model_response if r != '生成失败'])}\")\n",
    "print(f\"- 使用设备: {device}\")\n",
    "print(f\"- 模型: Qwen2-1.5B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6858179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 DPO训练参数:\n",
      "- 训练轮数: 3\n",
      "- 训练数据量: 50\n",
      "- 支持真人化比例: 0.2 (20.0% 支持, 80.0% 反对)\n"
     ]
    }
   ],
   "source": [
    "# DPO微调参数设置\n",
    "# 只需要修改这个模块，不需要改变其他的，除非真的知道自己在做什么。\n",
    "\n",
    "num_epoch = 3      # 训练轮数\n",
    "data_size = 50      # 用于训练的数据量\n",
    "support_ratio = 0.2 # 偏好支持真人化的比例\n",
    "\n",
    "# support_ratio 将反映人类的偏好：\n",
    "# 0 表示完全不支持（反对）真人化\n",
    "# 1 表示完全支持真人化\n",
    "# 0.1 表示 10% 支持真人化， 90% 反对。\n",
    "\n",
    "print(f\"📊 DPO训练参数:\")\n",
    "print(f\"- 训练轮数: {num_epoch}\")\n",
    "print(f\"- 训练数据量: {data_size}\")\n",
    "print(f\"- 支持真人化比例: {support_ratio} ({support_ratio*100}% 支持, {(1-support_ratio)*100}% 反对)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47aafa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 数据分布:\n",
      "- 总训练数据: 50\n",
      "- 支持真人化的数据: 10\n",
      "- 反对真人化的数据: 40\n",
      "\n",
      "📋 训练数据集预览 (前5行):\n",
      "  position                preferred                non-preferred\n",
      "0  support  真人化能夠呈現更真實的角色形象，提升原作魅力。  真人化可能無法完美呈現動畫中的獨特風格，損害原作形象。\n",
      "1  support  真人化能夠讓更多非動漫迷接觸作品，擴大影響力。      真人化可能失去動漫的獨特風格，限制影響力擴大。\n",
      "2  support    真人化能夠吸引不熟悉動漫的觀眾，擴大受眾。    真人化可能讓原本的動漫迷感到失望，無法吸引新觀眾。\n",
      "3  support    真人化有機會更深入挖掘原作故事，保留精髓。      真人化可能因為改編而失去原作故事的深度與精髓。\n",
      "4  support    真人化能夠開拓更多商業機會，提升產業價值。      真人化可能讓觀眾對原作失去興趣，影響產業價值。\n",
      "\n",
      "✅ 训练数据集准备完成!\n",
      "- 数据集大小: 50\n",
      "- 总共有 50 笔训练数据\n",
      "- 当 support_ratio 设置为 0.2 时:\n",
      "  * 前 10 笔数据偏好支持真人化\n",
      "  * 后 40 笔数据偏好反对真人化\n"
     ]
    }
   ],
   "source": [
    "# 准备训练数据\n",
    "\n",
    "# 选择部分数据用于训练\n",
    "training_data = full_data[:data_size]\n",
    "\n",
    "# 定义 support 数据集的大小，用于将一部分数据标记为\"支持\" (chosen)，另一部分标记为\"反对\" (rejected)\n",
    "support_data_size = int(data_size * support_ratio)\n",
    "\n",
    "print(f\"📈 数据分布:\")\n",
    "print(f\"- 总训练数据: {data_size}\")\n",
    "print(f\"- 支持真人化的数据: {support_data_size}\")\n",
    "print(f\"- 反对真人化的数据: {data_size - support_data_size}\")\n",
    "\n",
    "# 为训练数据集准备数据\n",
    "prompt_list = [data_formulate(data) for data in training_data]\n",
    "chosen_list = [data['support'] for data in training_data[:support_data_size]] + [data['oppose'] for data in training_data[support_data_size:]]\n",
    "rejected_list = [data['oppose'] for data in training_data[:support_data_size]] + [data['support'] for data in training_data[support_data_size:]]\n",
    "position_list = ['support' for _ in range(support_data_size)] + ['oppose' for _ in range(data_size - support_data_size)]\n",
    "\n",
    "# 创建训练数据集\n",
    "train_dataset = Dataset.from_dict({'prompt': prompt_list, 'position': position_list, 'chosen': chosen_list, 'rejected': rejected_list})\n",
    "\n",
    "# 显示数据集预览\n",
    "import pandas as pd\n",
    "df_preview = pd.DataFrame(train_dataset).rename(columns={\"chosen\": \"preferred\", \"rejected\": \"non-preferred\"})\n",
    "print(f\"\\n📋 训练数据集预览 (前5行):\")\n",
    "print(df_preview[['position', 'preferred', 'non-preferred']].head())\n",
    "\n",
    "print(f\"\\n✅ 训练数据集准备完成!\")\n",
    "print(f\"- 数据集大小: {len(train_dataset)}\")\n",
    "print(f\"- 总共有 {data_size} 笔训练数据\")\n",
    "print(f\"- 当 support_ratio 设置为 {support_ratio} 时:\")\n",
    "print(f\"  * 前 {support_data_size} 笔数据偏好支持真人化\")\n",
    "print(f\"  * 后 {data_size - support_data_size} 笔数据偏好反对真人化\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53554820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 设置训练参数...\n",
      "训练设备: mps\n",
      "✅ DPO训练参数设置完成\n",
      "✅ PEFT (LoRA) 配置完成\n",
      "\n",
      "📋 训练配置总览:\n",
      "- 训练轮数: 3\n",
      "- 批大小: 1\n",
      "- 梯度累积步数: 8\n",
      "- 学习率: 0.0002\n",
      "- LoRA rank: 64\n",
      "- LoRA alpha: 16\n"
     ]
    }
   ],
   "source": [
    "# 训练配置\n",
    "\n",
    "print(\"🔧 设置训练参数...\")\n",
    "\n",
    "# 确保使用正确的设备\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"训练设备: {device}\")\n",
    "\n",
    "# DPO训练配置 - 针对MacBook Air M4优化\n",
    "training_args = DPOConfig(\n",
    "    output_dir='./',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=num_epoch,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=False,\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"adamw_torch\",  # 使用标准AdamW优化器，避免8bit问题\n",
    "    logging_steps=1,\n",
    "    warmup_ratio=0.1,\n",
    "    beta=0.1,\n",
    "    report_to='none',\n",
    "    \n",
    "    # 显式声明以避免警告\n",
    "    max_length=512,\n",
    "    max_prompt_length=128,\n",
    "    remove_unused_columns=False,\n",
    "    \n",
    "    # MacBook Air M4兼容性设置\n",
    "    fp16=False,  # 禁用fp16\n",
    "    bf16=False,  # 禁用bf16\n",
    "    dataloader_pin_memory=False,  # 禁用内存固定\n",
    "    use_cpu=True if device == \"cpu\" else False,  # CPU模式\n",
    ")\n",
    "\n",
    "print(\"✅ DPO训练参数设置完成\")\n",
    "\n",
    "# PEFT配置 - Parameter-Efficient Fine-Tuning\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "print(\"✅ PEFT (LoRA) 配置完成\")\n",
    "\n",
    "print(f\"\\n📋 训练配置总览:\")\n",
    "print(f\"- 训练轮数: {num_epoch}\")\n",
    "print(f\"- 批大小: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"- 梯度累积步数: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"- 学习率: {training_args.learning_rate}\")\n",
    "print(f\"- LoRA rank: {peft_config.r}\")\n",
    "print(f\"- LoRA alpha: {peft_config.lora_alpha}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d14647a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 初始化DPO训练器...\n",
      "将模型移动到设备: mps\n",
      "⚠️  MPS在DPO训练时可能不稳定，建议使用CPU\n",
      "✅ 已切换到CPU进行训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prompt in train dataset: 100%|██████████| 50/50 [00:00<00:00, 12780.50 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 50/50 [00:00<00:00, 20319.27 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 50/50 [00:00<00:00, 4502.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DPO训练器初始化完成\n",
      "\n",
      "🔥 开始DPO训练...\n",
      "- 训练数据量: 50\n",
      "- 训练轮数: 3\n",
      "- 支持比例: 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 02:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.686900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.545900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.606900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.586400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.551200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.512200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.622800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 DPO训练完成!\n",
      "- 训练耗时: 177.67秒\n",
      "- 平均每轮: 59.22秒\n"
     ]
    }
   ],
   "source": [
    "# 初始化DPO训练器并开始训练\n",
    "\n",
    "print(\"🚀 初始化DPO训练器...\")\n",
    "\n",
    "# 确保模型在正确的设备上\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"将模型移动到设备: {device}\")\n",
    "\n",
    "# 如果使用CPU训练，将模型移动到CPU\n",
    "if device == \"cpu\":\n",
    "    model = model.to(\"cpu\")\n",
    "    print(\"✅ 模型已移动到CPU\")\n",
    "elif device == \"mps\":\n",
    "    # MPS可能在训练时有兼容性问题，建议使用CPU\n",
    "    print(\"⚠️  MPS在DPO训练时可能不稳定，建议使用CPU\")\n",
    "    model = model.to(\"cpu\")\n",
    "    device = \"cpu\"\n",
    "    print(\"✅ 已切换到CPU进行训练\")\n",
    "\n",
    "# 初始化 DPO 训练器\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "print(\"✅ DPO训练器初始化完成\")\n",
    "\n",
    "print(f\"\\n🔥 开始DPO训练...\")\n",
    "print(f\"- 训练数据量: {len(train_dataset)}\")\n",
    "print(f\"- 训练轮数: {num_epoch}\")\n",
    "print(f\"- 支持比例: {support_ratio}\")\n",
    "\n",
    "# 开始训练\n",
    "import time\n",
    "train_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    dpo_trainer.train()\n",
    "    train_elapsed = time.time() - train_start_time\n",
    "    print(f\"\\n🎉 DPO训练完成!\")\n",
    "    print(f\"- 训练耗时: {train_elapsed:.2f}秒\")\n",
    "    print(f\"- 平均每轮: {train_elapsed/num_epoch:.2f}秒\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 训练过程中出现错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8016bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 测试训练后的模型效果...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "真人化是否能改善日本漫畫的全球可及性？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:26,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化可以增加漫畫的吸引力和接受度。\n",
      "\n",
      "Question 2:\n",
      "真人化如何影響年輕一代對日本漫畫的看法？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:05<00:24,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "真人化增加漫畫知名度，但可能淡化原作深度。\n",
      "\n",
      "Question 3:\n",
      "真人化是否能提升原作漫畫的文學價值？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:17,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "不一定，視情況而定。\n",
      "\n",
      "Question 4:\n",
      "真人化是否有助於保護和保存日本漫畫的傳統？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:11<00:16,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化有助於保持原汁原味。\n",
      "\n",
      "Question 5:\n",
      "真人化是否有助於提升日本漫畫行業的經濟效益？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:13<00:13,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化可以增加收視率和票房收益。\n",
      "\n",
      "Question 6:\n",
      "真人化如何影響日本漫畫原作者的創作動力？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:15<00:09,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "真人化可能降低創作動力。\n",
      "\n",
      "Question 7:\n",
      "真人化是否對漫畫原作的忠實粉絲公平？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:17<00:07,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "真人化可能削弱原作的深度和深度。\n",
      "\n",
      "Question 8:\n",
      "真人化是否能夠促進日本漫畫的創新和多樣性？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:20<00:04,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化有助於更多元化和創新。\n",
      "\n",
      "Question 9:\n",
      "真人化是否有助於擴大動漫文化的市場份額？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:22<00:02,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化可以增加觀眾吸引力。\n",
      "\n",
      "Question 10:\n",
      "真人化是否有助於提高日本漫畫在全球的競爭力？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from trained model:\n",
      "是的，真人化可以增加觀眾的吸引力。\n",
      "\n",
      "✅ 训练后模型测试完成!\n",
      "- 成功回答: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试训练后的模型\n",
    "\n",
    "print(\"🧪 测试训练后的模型效果...\")\n",
    "\n",
    "trained_model_response = []\n",
    "\n",
    "# 确定设备\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "for data in tqdm(test_data):\n",
    "    id = data['id']\n",
    "    print(f\"Question {id}:\\n{data['prompt']}\")\n",
    "\n",
    "    # 处理输入 - 适配Qwen2和MPS设备\n",
    "    inputs = tokenizer(data_formulate(data), return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    generation_config = GenerationConfig(\n",
    "        do_sample=False,\n",
    "        max_new_tokens=50,  # 保持与原始测试一致的长度\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, generation_config=generation_config)\n",
    "        \n",
    "        output_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "        prompt_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
    "        \n",
    "        # 提取回答 - 适配Qwen2模型格式\n",
    "        if 'assistant' in output_text:\n",
    "            parts = output_text.split('assistant')\n",
    "            if len(parts) > 1:\n",
    "                response = parts[-1].strip()\n",
    "            else:\n",
    "                response = output_text.replace(prompt_text, '').strip()\n",
    "        else:\n",
    "            response = output_text.replace(prompt_text, '').strip()\n",
    "        \n",
    "        trained_model_response.append(response)\n",
    "        print(f\"Response from trained model:\\n{response}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成失败: {e}\")\n",
    "        trained_model_response.append(\"生成失败\")\n",
    "    \n",
    "    # 内存清理\n",
    "    if device == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "print(f\"✅ 训练后模型测试完成!\")\n",
    "print(f\"- 成功回答: {len([r for r in trained_model_response if r != '生成失败'])}/{len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98b3a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 对比训练前后的模型回答...\n",
      "\n",
      "🔍 详细对比结果:\n",
      "================================================================================\n",
      "\n",
      "问题 1: 真人化是否能改善日本漫畫的全球可及性？\n",
      "原始模型: 是的，真人化可以增加漫畫的視覺吸引力和可觀賞性。\n",
      "训练后模型: 是的，真人化可以增加漫畫的吸引力和接受度。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 2: 真人化如何影響年輕一代對日本漫畫的看法？\n",
      "原始模型: 真人化使漫畫更接近生活，吸引年輕觀眾。\n",
      "训练后模型: 真人化增加漫畫知名度，但可能淡化原作深度。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 3: 真人化是否能提升原作漫畫的文學價值？\n",
      "原始模型: 真人化可以增加觀眾的接觸度，但不一定提升原作的文學價值。\n",
      "训练后模型: 不一定，視情況而定。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 4: 真人化是否有助於保護和保存日本漫畫的傳統？\n",
      "原始模型: 是的，真人化有助於保持漫畫的傳統風格和故事性。\n",
      "训练后模型: 是的，真人化有助於保持原汁原味。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 5: 真人化是否有助於提升日本漫畫行業的經濟效益？\n",
      "原始模型: 是的，真人化可以增加觀眾吸引力和收視率。\n",
      "训练后模型: 是的，真人化可以增加收視率和票房收益。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 6: 真人化如何影響日本漫畫原作者的創作動力？\n",
      "原始模型: 真人化增加創作靈感，但可能影響創作風格。\n",
      "训练后模型: 真人化可能降低創作動力。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 7: 真人化是否對漫畫原作的忠實粉絲公平？\n",
      "原始模型: 真人化可能影響原作的深度和細節。\n",
      "训练后模型: 真人化可能削弱原作的深度和深度。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 8: 真人化是否能夠促進日本漫畫的創新和多樣性？\n",
      "原始模型: 是的，真人化有助於展現更多樣性。\n",
      "训练后模型: 是的，真人化有助於更多元化和創新。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 9: 真人化是否有助於擴大動漫文化的市場份額？\n",
      "原始模型: 是的，真人化可以增加動漫的吸引力和接受度。\n",
      "训练后模型: 是的，真人化可以增加觀眾吸引力。\n",
      "------------------------------------------------------------\n",
      "\n",
      "问题 10: 真人化是否有助於提高日本漫畫在全球的競爭力？\n",
      "原始模型: 是的，真人化可以增加漫畫的吸引力和接受度。\n",
      "训练后模型: 是的，真人化可以增加觀眾的吸引力。\n",
      "------------------------------------------------------------\n",
      "\n",
      "✅ 结果已保存:\n",
      "📄 对比数据 (JSON): ./results/dpo_comparison_20250807_134522.json\n",
      "📝 训练报告 (TXT): ./results/dpo_training_report_20250807_134522.txt\n",
      "\n",
      "📈 训练总结:\n",
      "- 使用模型: Qwen2-1.5B-Instruct\n",
      "- 训练方法: DPO (Direct Preference Optimization)\n",
      "- 训练数据: 50 条\n",
      "- 偏好设置: 20.0% 支持真人化\n",
      "- 测试问题: 10 个\n",
      "- 设备: mps\n"
     ]
    }
   ],
   "source": [
    "# 对比训练前后的结果并保存\n",
    "\n",
    "print(\"📊 对比训练前后的模型回答...\")\n",
    "\n",
    "# 创建对比数据\n",
    "comparison_data = {\n",
    "    \"model_name\": \"Qwen2-1.5B-Instruct\",\n",
    "    \"model_path\": \"../week06/cache/Qwen2-1.5B-Instruct\",\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"training_params\": {\n",
    "        \"num_epoch\": num_epoch,\n",
    "        \"data_size\": data_size,\n",
    "        \"support_ratio\": support_ratio\n",
    "    },\n",
    "    \"device\": device,\n",
    "    \"comparisons\": []\n",
    "}\n",
    "\n",
    "print(f\"\\n🔍 详细对比结果:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, data in enumerate(test_data):\n",
    "    original_resp = original_model_response[i] if i < len(original_model_response) else \"未生成\"\n",
    "    trained_resp = trained_model_response[i] if i < len(trained_model_response) else \"未生成\"\n",
    "    \n",
    "    comparison_item = {\n",
    "        \"id\": data['id'],\n",
    "        \"question\": data['prompt'],\n",
    "        \"original_response\": original_resp,\n",
    "        \"trained_response\": trained_resp\n",
    "    }\n",
    "    comparison_data[\"comparisons\"].append(comparison_item)\n",
    "    \n",
    "    print(f\"\\n问题 {data['id']}: {data['prompt']}\")\n",
    "    print(f\"原始模型: {original_resp}\")\n",
    "    print(f\"训练后模型: {trained_resp}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# 保存对比结果\n",
    "results_dir = \"./results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "comparison_filename = f\"{results_dir}/dpo_comparison_{timestamp}.json\"\n",
    "\n",
    "with open(comparison_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(comparison_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 保存详细的文本报告\n",
    "report_filename = f\"{results_dir}/dpo_training_report_{timestamp}.txt\"\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"DPO训练报告 - Qwen2-1.5B-Instruct\\n\")\n",
    "    f.write(f\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"时间: {timestamp}\\n\")\n",
    "    f.write(f\"模型: Qwen2-1.5B-Instruct\\n\")\n",
    "    f.write(f\"设备: {device}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"训练参数:\\n\")\n",
    "    f.write(f\"- 训练轮数: {num_epoch}\\n\")\n",
    "    f.write(f\"- 训练数据量: {data_size}\\n\")\n",
    "    f.write(f\"- 支持真人化比例: {support_ratio}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"结果对比:\\n\")\n",
    "    f.write(f\"-\"*50 + \"\\n\")\n",
    "    \n",
    "    for i, data in enumerate(test_data):\n",
    "        original_resp = original_model_response[i] if i < len(original_model_response) else \"未生成\"\n",
    "        trained_resp = trained_model_response[i] if i < len(trained_model_response) else \"未生成\"\n",
    "        \n",
    "        f.write(f\"\\n问题 {data['id']}: {data['prompt']}\\n\")\n",
    "        f.write(f\"原始模型: {original_resp}\\n\")\n",
    "        f.write(f\"训练后模型: {trained_resp}\\n\")\n",
    "        f.write(f\"-\"*30 + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ 结果已保存:\")\n",
    "print(f\"📄 对比数据 (JSON): {comparison_filename}\")\n",
    "print(f\"📝 训练报告 (TXT): {report_filename}\")\n",
    "\n",
    "print(f\"\\n📈 训练总结:\")\n",
    "print(f\"- 使用模型: Qwen2-1.5B-Instruct\")\n",
    "print(f\"- 训练方法: DPO (Direct Preference Optimization)\")\n",
    "print(f\"- 训练数据: {data_size} 条\")\n",
    "print(f\"- 偏好设置: {support_ratio*100}% 支持真人化\")\n",
    "print(f\"- 测试问题: {len(test_data)} 个\")\n",
    "print(f\"- 设备: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff53d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661bd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4930724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a388fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
