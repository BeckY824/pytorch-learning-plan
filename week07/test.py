# test.py
import os
import json
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig
from peft import PeftModel
from utils import evaluate, print_results_sample
from config import (
    DEVICE, MODEL_PATH, CKPT_PATH, TEST_DATA_PATH, OUTPUT_DIR,
    MAX_LEN, TEMPERATURE, TOP_P, NO_REPEAT_NGRAM_SIZE
)


def test():
    print("\nğŸš€ å¼€å§‹ LoRA æ¨¡å‹æµ‹è¯•")

    # âœ… åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, "results.txt")

    # âœ… åŠ è½½ Tokenizer
    print("ğŸ“š åŠ è½½ tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, add_eos_token=True)
    tokenizer.pad_token = tokenizer.eos_token

    # âœ… åŠ è½½åŸºç¡€æ¨¡å‹
    print("ğŸ“š åŠ è½½åŸºç¡€æ¨¡å‹...")
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        torch_dtype=torch.float32,
        device_map=None,
        low_cpu_mem_usage=True
    )

    # âœ… åŠ è½½ LoRA æƒé‡
    print("ğŸ”§ åŠ è½½ LoRA å¾®è°ƒæƒé‡...")
    model = PeftModel.from_pretrained(model, CKPT_PATH, torch_dtype=torch.float32)
    model.to(DEVICE)
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå‚æ•°ç±»å‹: {next(model.parameters()).dtype}")

    # âœ… ç”Ÿæˆé…ç½®
    generation_config = GenerationConfig(
        do_sample=True,
        temperature=TEMPERATURE,
        num_beams=1,
        top_p=TOP_P,
        no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,
        pad_token_id=tokenizer.pad_token_id
    )

    # âœ… è¯»å–æµ‹è¯•æ•°æ®
    with open(TEST_DATA_PATH, "r", encoding="utf-8") as f:
        test_datas = json.load(f)
    print(f"ğŸ“– è¯»å– {len(test_datas)} ä¸ªæµ‹è¯•æ ·ä¾‹")

    # âœ… ç”Ÿæˆç»“æœ
    results = []
    with open(output_path, "w", encoding="utf-8") as f:
        for i, data in enumerate(test_datas):
            print(f"\nâ¡ï¸ ç¬¬ {i+1}/{len(test_datas)} ä¸ªæ ·ä¾‹: {data['input']}")
            try:
                output = evaluate(data["instruction"], generation_config, MAX_LEN, data["input"], tokenizer, model)
                result_line = f"{i+1}. {data['input']}{output}"
                f.write(result_line + "\n")
                print(f"ç”Ÿæˆ: {output}")
                results.append({"input": data["input"], "output": output, "full_poem": result_line})
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
                f.write(f"{i+1}. {data['input']} [ç”Ÿæˆå¤±è´¥: {e}]\n")

    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨:", output_path)
    print_results_sample(results)


if __name__ == "__main__":
    test()