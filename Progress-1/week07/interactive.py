#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤äº’å¼å¯¹è¯ç•Œé¢
ä¸å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œå®æ—¶äº¤äº’
"""

import os
import torch
from transformers import GenerationConfig
from config import *
from model_utils import load_model, load_tokenizer, load_finetuned_model
from evaluate import evaluate, create_generation_config

def interactive_chat():
    """äº¤äº’å¼èŠå¤©åŠŸèƒ½"""
    print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–äº¤äº’å¼å¯¹è¯ç³»ç»Ÿ...")
    print(f"å½“å‰æ¨¡å‹: {CURRENT_MODEL}")
    print(f"æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"æ£€æŸ¥ç‚¹: {CKPT_DIR}")
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    try:
        tokenizer = load_tokenizer()
        base_model = load_model()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾®è°ƒæƒé‡
        if os.path.exists(CKPT_DIR) and any(f.endswith('.bin') or f.endswith('.safetensors') for f in os.listdir(CKPT_DIR)):
            print("ğŸ”§ åŠ è½½å¾®è°ƒæƒé‡...")
            model = load_finetuned_model(base_model, CKPT_DIR)
            print("âœ… å¾®è°ƒæ¨¡å‹åŠ è½½å®Œæˆ")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°å¾®è°ƒæƒé‡ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹")
            model = base_model
        
        # åˆ›å»ºç”Ÿæˆé…ç½®
        generation_config = create_generation_config(
            temperature=TEMPERATURE,
            top_p=TOP_P,
            no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE
        )
        generation_config.pad_token_id = tokenizer.pad_token_id
        
        print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # å¼€å§‹äº¤äº’
    print("\n" + "="*50)
    print("ğŸ­ æ¬¢è¿ä½¿ç”¨å”è¯—ç”Ÿæˆäº¤äº’ç³»ç»Ÿ")
    print("ğŸ’¡ è¾“å…¥ä½ çš„æŒ‡ä»¤ï¼Œç³»ç»Ÿå°†ä¸ºä½ ç”Ÿæˆå”è¯—")
    print("ğŸ’¡ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("ğŸ’¡ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
    print("ğŸ’¡ è¾“å…¥ 'clear' æ¸…å±")
    print("="*50)
    
    conversation_history = []
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input("\nğŸ§‘ ä½ : ").strip()
            
            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            elif user_input.lower() in ['help', 'å¸®åŠ©']:
                print_help()
                continue
            elif user_input.lower() in ['clear', 'æ¸…å±']:
                os.system('clear' if os.name == 'posix' else 'cls')
                continue
            elif user_input.lower() in ['history', 'å†å²']:
                print_history(conversation_history)
                continue
            elif user_input.lower() in ['config', 'é…ç½®']:
                print_config()
                continue
            elif not user_input:
                print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„æŒ‡ä»¤")
                continue
            
            # ç”Ÿæˆå“åº”
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆ...")
            try:
                response = evaluate(
                    instruction=user_input,
                    tokenizer=tokenizer,
                    model=model,
                    generation_config=generation_config,
                    max_len=MAX_LEN,
                    input_text="",
                    verbose=False
                )
                
                print(f"ğŸ¤– æ¨¡å‹: {response}")
                
                # ä¿å­˜å¯¹è¯å†å²
                conversation_history.append({
                    "user": user_input,
                    "assistant": response
                })
                
                # é™åˆ¶å†å²è®°å½•é•¿åº¦
                if len(conversation_history) > 10:
                    conversation_history.pop(0)
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("\nğŸ“š å¸®åŠ©ä¿¡æ¯:")
    print("quit/exit - é€€å‡ºç¨‹åº")
    print("help - æ˜¾ç¤ºå¸®åŠ©")
    print("clear - æ¸…å±")
    print("history - æ˜¾ç¤ºå¯¹è¯å†å²")
    print("config - æ˜¾ç¤ºå½“å‰é…ç½®")
    print("\nğŸ’¡ ç¤ºä¾‹æŒ‡ä»¤:")
    print("- å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„å”è¯—")
    print("- è¯·åˆ›ä½œä¸€é¦–æå†™æœˆäº®çš„è¯—")
    print("- å†™ä¸€é¦–å…³äºå±±æ°´çš„äº”è¨€å¾‹è¯—")

def print_history(history):
    """æ‰“å°å¯¹è¯å†å²"""
    if not history:
        print("ğŸ“ æš‚æ— å¯¹è¯å†å²")
        return
    
    print("\nğŸ“ å¯¹è¯å†å²:")
    for i, item in enumerate(history, 1):
        print(f"{i}. ğŸ§‘: {item['user']}")
        print(f"   ğŸ¤–: {item['assistant']}")
        print("-" * 40)

def print_config():
    """æ‰“å°å½“å‰é…ç½®"""
    print(f"\nâš™ï¸ å½“å‰é…ç½®:")
    print(f"æ¨¡å‹: {CURRENT_MODEL}")
    print(f"æ¸©åº¦: {TEMPERATURE}")
    print(f"Top-P: {TOP_P}")
    print(f"æœ€å¤§é•¿åº¦: {MAX_LEN}")
    print(f"è®¾å¤‡: {DEVICE}")

def main():
    """ä¸»å‡½æ•°"""
    interactive_chat()

if __name__ == "__main__":
    main() 