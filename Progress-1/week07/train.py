# train.py
import torch
from transformers import TrainingArguments, Trainer
from config import *
from model_utils import load_model, load_tokenizer, apply_lora
from data_utils import load_and_preprocess_data, create_data_collator

def train():
    """
    æ‰§è¡Œæ¨¡å‹å¾®è°ƒè®­ç»ƒ
    """
    print("ğŸš€ å¼€å§‹ LoRA å¾®è°ƒè®­ç»ƒ")
    print(f"ğŸ”§ å½“å‰æ¨¡å‹: {CURRENT_MODEL}")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"ğŸ“Š æ•°æ®é›†: {DATASET_PATH}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {CKPT_DIR}")
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    model = load_model()
    tokenizer = load_tokenizer()
    
    # åº”ç”¨LoRAé…ç½®
    model = apply_lora(model)
    
    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    train_data, val_data = load_and_preprocess_data(tokenizer, DATASET_PATH, NUM_TRAIN_DATA)
    
    # åˆ›å»ºæ•°æ®æ”¶é›†å™¨
    data_collator = create_data_collator()
    
    # è®­ç»ƒå‚æ•°
    training_args = TrainingArguments(
        output_dir=CKPT_DIR,
        per_device_train_batch_size=MICRO_BATCH_SIZE,
        gradient_accumulation_steps=GRAD_ACC_STEPS,
        learning_rate=LEARNING_RATE,
        num_train_epochs=EPOCHS,
        logging_steps=20,
        save_steps=65,
        save_total_limit=3,
        fp16=False,  # åœ¨MPSä¸Šä½¿ç”¨float32
        dataloader_pin_memory=False,
        report_to="none",
        remove_unused_columns=False,
        eval_strategy="no",  # æš‚æ—¶ä¸ä½¿ç”¨è¯„ä¼°
        save_strategy="steps",
        logging_first_step=True,
        load_best_model_at_end=False,
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_data,
        eval_dataset=val_data,
        data_collator=data_collator,
    )
    
    # ç¦ç”¨ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
    model.config.use_cache = False
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸƒ å¼€å§‹è®­ç»ƒ...")
    try:
        trainer.train()
        print("âœ… è®­ç»ƒå®Œæˆ")
        
        # ä¿å­˜æ¨¡å‹
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {CKPT_DIR}")
        model.save_pretrained(CKPT_DIR)
        tokenizer.save_pretrained(CKPT_DIR)
        print("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        raise

def main():
    """
    ä¸»å‡½æ•°
    """
    train()

if __name__ == "__main__":
    main()