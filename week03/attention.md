# 注意力(Attention)

## 神经网络

1. 基础的神经网络为MLP（多层感知机）

   其结构就是输入层 -----> 隐藏层 ----> 输出层

   每层之间使用全连接（Fully Connected）层 + 激活函数（relu）

   每层神经元与上下层的每一个神经元是完全连接的

   > 全连接设计初衷：在对输入没有任何**先验结构知识**的前提下，通过让每层神经元都连接所有输入，使模型具备**最大的信息流动能力与表达能力**，从而能逼近任何复杂函数。

   > 线性层是“搬运工”，只能对信息加权合并。
   >
   > 激活函数是“加工机器”，赋予信息复杂的形态变化能力。
   >
   > 没有激活函数，所有搬运在多次，还是没加工。

2. 为什么采用全连接？

   - 通用性：没有结构假设时的默认选择

     在图像、序列、图结构等任务中，我们有空间，时间等结构可以利用。

     在最通用的情况，比如表格数据、抽象特征输入时，我们对输入之间没有空间顺序/局部结构一无所知。

     那就只能让每个神经元都试试看所有输入，避免信息丢失。

   - 理论支持：通用逼近定理

     数学上有个经典结论，**任意连续函数都可以用一层隐藏层的全连接神经网络逼近**，前提是激活函数非线形且宽度足够。

3. 什么是激活函数？

   - 打破线性限制

     没有激活函数的神经网络本质是多个线性层的组合仍然是一个线性变换。

     这样的网络**再深也学不会复杂的决策边界**，只能你和线性可分的任务。

     引入激活函数，则变为深度学习，**每层都在非线形地提取抽象特征**。

   - 帮助神经网络拟合复杂的函数

     比如图像分类，语音识别、自然语言处理等任务，输入和输出之间都是高度非线形关系。

     激活函数可以让网络学习 ”非线形映射“，逐层提取越来越抽象的特征。

   - 引入非线形决策边界

     对于分类任务，比如将点分为两个类别，线性模型只能**画一条直线**来分。

     引入激活函数后，神经网络可以学习出**弯曲、复杂的边界**。

## 前馈神经网络

Feedforward Neural Network，FNN/FFN

MLP是前馈神经网络最典型、最基本的一种。

           ┌────────────┐
           │ 前馈神经网络 │  ← 大概念（Feedforward NN）
           └────┬───────┘
                │
      ┌─────────▼──────────┐
      │   多层感知机 MLP     │  ← 最常见的前馈结构
      └─────────┬──────────┘
                │
      ┌─────────▼─────────┐
      │  基础神经网络（常指它）│  ← 教科书里的初学模型
      └───────────────────┘



## 注意力机制

即，我们往往无需看清楚全部内容，而仅将注意力集中在重点部分即可。

具体而言，注意力机制的特点是通过计算 **Query**与**Key**的相关性为真值加权求和，从而拟合序列中每个词同其他词的相关关系。

### 深入理解注意力机制

三个核心变量 ：查询值 Query， 键值 Key 和 真值 Value。

```json
{
    "apple":10,
    "banana":5,
    "chair":2
}
```

我们如果想要匹配的Query是一个包含多个Key的概念？例如，“fruit”，此时，我们应该将apple和banana都匹配到，但不能匹配到chair。因此，我们往往会将Key对应的Value进行组合得到最终的Value。

权重赋值如下。

```json
{
    "apple":0.6,
    "banana":0.4,
    "chair":0
}
```

我们最终查询到的值应该是：
$$
value = 0.6 * 10 + 0.4 * 5 + 0 * 2 = 8
$$
直观上，Key与Query相关性越高，则其所赋予的注意力权重就越大。

向量之间，使用点积来衡量相似性。语义相似，点击应该大于0，而语义不相似应该小于0。
$$
x = qK^T
$$
可以通过一个 Softmax 层将其转换为1的权重。

注意力机制的基本公式：
$$
attention(Q,K,V) = softmax(qK^T)v
$$
此时的值还是一个标量，同时，我们此次只查询了一个Query。我们可以将值转换为维度为 d~v~ ，同时一次查询多个Query，同样将多个Query对应的词向量堆叠在一起形成一个矩阵Q，得到：
$$
attention(Q,K,V) = softmax(QK^T)V
$$
如果**Q和K对应的维度d~k~ 比较大**，softmax 缩放时就非常容易影响，使不同值之间的差异较大，从而影响梯度的稳定性。因此，我们要将Q和K乘积的结果做一个放缩：
$$
attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d~k~}}V)
$$

> 当d~k~ 很大时，QK^T^ 的值会非常大，造成：
>
> - softmax的指数部分爆炸（例如 e^50^ =5.185×10²¹)
> - 结果接近 one-hot 分布，梯度消失或爆炸
> - 训练过程变得不稳定
>
> 这个技巧类似于BatchNorm，LayerNorm的动机：控制数值分布，帮助训练稳定。

### 自注意力

实际应用中，我们往往只需要计算Query和Key之间的注意力结果，很少存在额外的真值Value。在Transfomer的Decoder结构中，Q来自于Decoder的输入，K和V来自于Encoder的输出，从而拟合了编码信息与历史信息之间的关系。

在Transformer的Encoder结构中，使用的是注意力机制的变种，自注意力（self- attention）。即是计算本身序列中**每个元素对其他元素的注意力分布**。Q、K、V都由同一个输入通过不同的参数矩阵计算得到。在Encoder中，Q、K、V分别是输入对参数矩阵 W~q~, W~k~, W~v~，做积得到，从而拟合输入语句中每一个token对其他所有token的关系。

通过自注意力机制，我们可以找一段文本中每个token与其他所有token的相关关系大小，从而建模文本之间的依赖关系。在代码中的实现，self-attention 机制其实是通过给 Q、K、V 的输入传入同一个参数实现的：

```python
# attention 为上文定义的注意力计算函数
attention(x, x, x)
```

### 掩码自注意力

Mask Self-Attention，使用注意力掩码的自注意力机制。作用是遮蔽一些特定位置的token，模型在学习的过程中，会忽略掉被遮蔽的token。

使用注意力机制的Transfomer模型，也是通过类似于 n-gram 的语言模型任务来学习的，也就是对一个文本序列，不断根据之间的token来预测下一个token，直到将整个文本序列补全。

n-gram：

```markup
Step 1：输入 【BOS】，输出 I
Step 2：输入 【BOS】I，输出 like
Step 3：输入 【BOS】I like，输出 you
Step 4：输入 【BOS】I like you，输出 【EOS】
```

transformer：

```markup
<BOS> 【MASK】【MASK】【MASK】【MASK】
<BOS>    I   【MASK】 【MASK】【MASK】
<BOS>    I     like  【MASK】【MASK】
<BOS>    I     like    you  【MASK】
<BoS>    I     like    you   </EOS>
```

在每一行输入中，模型只看到前面的token，预测下一个token。上述过程不再是串行的过程，而是可以一起并行地输入到模型中。模型只需要每一个样本根据未被遮蔽的token来预测下一个token即可，从而实现了并行的语言模型。

